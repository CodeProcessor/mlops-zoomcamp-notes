{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c51efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef880a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7836ccfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dulanj/miniconda3/envs/mlops9/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DictVectorizer from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/dulanj/miniconda3/envs/mlops9/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LinearRegression from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, lr = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41c08294",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4854399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "month = 2\n",
    "input_file = f'https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_{year:04d}-{month:02d}.parquet'\n",
    "output_file = f\"predictions_{year:04d}-{month:02d}_fvh_data.parquet\"\n",
    "df = read_data(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "669fda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts)\n",
    "y_pred = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36293d04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer for Q1: 16.19\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mean  = round(np.mean(y_pred), 2)\n",
    "print(f\"Answer for Q1: {mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c861b513",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81dec1d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'ride_id': df['ride_id'].values,\n",
    "    'predictions': y_pred\n",
    "}\n",
    "df_result = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12553d76",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘output’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!mkdir output\n",
    "df_result.to_parquet(\n",
    "    os.path.join(\"output\", output_file),\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51275e34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'predictions_2021-02_fvh_data.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [36]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# print size of the file\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m size_in_bytes \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetsize\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnswer for Q2 : File size in MB: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msize_in_bytes\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m1000000\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/mlops9/lib/python3.9/genericpath.py:50\u001B[0m, in \u001B[0;36mgetsize\u001B[0;34m(filename)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgetsize\u001B[39m(filename):\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mst_size\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'predictions_2021-02_fvh_data.parquet'"
     ]
    }
   ],
   "source": [
    "# print size of the file\n",
    "import os\n",
    "size_in_bytes = os.path.getsize(output_file)\n",
    "print(f\"Answer for Q2 : File size in MB: {size_in_bytes/1000000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0bdae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}